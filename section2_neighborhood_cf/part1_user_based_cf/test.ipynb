{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 1: User-Based Collaborative Filtering\n",
        "\n",
        "---\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook implements part 1: user-based collaborative filtering.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set visualization style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "# TODO: Add data loading code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# section 2 part 1 case study 1 point 10\n",
        "#on question 10 , can we trust the users who rated only the \n",
        "#common items more than the ones that rated more than the common items   ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# adjustment to main py file case_study_1.py\n",
        "\n",
        "# 10. Trust: Common items vs More items\n",
        "    print(\"\\n10. Trust Analysis (Common vs More Items):\")\n",
        "\n",
        "  # This is a discussion point, but we can find examples.\n",
        "    # Find a neighbor with high overlap but low total items vs low overlap but high total items?\n",
        "    # Or rather: \"rated the common items\" (subset) vs \"rated more items than the common items\" (superset)\n",
        "    # If User A has items {1,2} and User B has {1,2,3,4}. If they agree on {1,2}, sim is 1.0.\n",
        "    # If User C has {1,2} and agrees.\n",
        "    # We can just print some stats for the perfect neighbors above.\n",
        "    \n",
        "    # 11. Low ratings but high cosine\n",
        "    for target_user in target_users:\n",
        "        print(f\"\\n  Analyzing Target User: {target_user}\")\n",
        "        neighbors = results[target_user]['neighbors_raw']\n",
        "        \n",
        "        subset_neighbors = []\n",
        "        superset_neighbors = []\n",
        "        \n",
        "        target_items = set(all_users_ratings[target_user].keys())\n",
        "        \n",
        "        for neighbor_id, score in neighbors:\n",
        "            neighbor_items = set(all_users_ratings[neighbor_id].keys())\n",
        "            common = target_items & neighbor_items\n",
        "            \n",
        "            # Check for strict subset (neighbor rated ONLY common items)\n",
        "            if len(neighbor_items) == len(common):\n",
        "                subset_neighbors.append((neighbor_id, score, len(common), len(neighbor_items)))\n",
        "            elif len(neighbor_items) > len(common):\n",
        "                superset_neighbors.append((neighbor_id, score, len(common), len(neighbor_items)))\n",
        "                \n",
        "        print(f\"    Subset Neighbors (Rated ONLY common items): {len(subset_neighbors)}\")\n",
        "        if subset_neighbors:\n",
        "            print(f\"    Top 5 Subset: {subset_neighbors[:5]}\")\n",
        "            \n",
        "        print(f\"    Superset Neighbors (Rated MORE than common items): {len(superset_neighbors)}\")\n",
        "        if superset_neighbors:\n",
        "            # Sort by count of extra items (total - common) desc ?\n",
        "            # Or just show first few high similarity ones\n",
        "            print(f\"    Top 5 Superset: {superset_neighbors[:5]}\")\n",
        "\n",
        "    print(\"\\n11. Low Ratings High Cosine Analysis:\")\n",
        "    # Check if any strong neighbor has low average rating but high similarity?\n",
        "    u_ex = target_users[0]\n",
        "    perfect_neighbors = [n for n in results[u_ex]['neighbors_raw'] if abs(n[1] - 1.0) < 1e-5]\n",
        "    for pid, score in perfect_neighbors[:5]:\n",
        "        p_ratings = list(all_users_ratings[pid].values())\n",
        "        p_avg = sum(p_ratings)/len(p_ratings)\n",
        "        t_ratings = list(all_users_ratings[u_ex].values())\n",
        "        t_avg = sum(t_ratings)/len(t_ratings)\n",
        "        print(f\"  User {pid}: Avg Rating={p_avg:.2f} vs Target Avg={t_avg:.2f} (Sim={score:.2f})\")\n",
        "\n",
        "    print(\"\\nAnalysis Complete.\")\n",
        "\n",
        "\n",
        "# Check if any perfect neighbor has low average rating but high similarity?\n",
        "    # Cosine is scale-independent? No, raw cosine is NOT scale independent. \n",
        "    # Raw cosine of (1,1) and (5,5) -> (1*5 + 1*5) / (sqrt(2)*sqrt(50)) = 10 / (1.414 * 7.07) = 10 / 10 = 1.0\n",
        "    # So yes, if one user rates everything 1 and another rates everything 5, raw cosine is 1.0.\n",
        "    # Let's verify this with data.\n",
        "        # Check if any strong neighbor has low average rating but high similarity?\n",
        "    u_ex = target_users[0]\n",
        "    perfect_neighbors = [n for n in results[u_ex]['neighbors_raw'] if abs(n[1] - 1.0) < 1e-5]\n",
        "    for pid, score in perfect_neighbors[:5]:\n",
        "        p_ratings = list(all_users_ratings[pid].values())\n",
        "        p_avg = sum(p_ratings)/len(p_ratings)\n",
        "        t_ratings = list(all_users_ratings[u_ex].values())\n",
        "        t_avg = sum(t_ratings)/len(t_ratings)\n",
        "        print(f\"  User {pid}: Avg Rating={p_avg:.2f} vs Target Avg={t_avg:.2f} (Sim={score:.2f})\")\n",
        "\n",
        "    print(\"\\nAnalysis Complete.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# seperate script created by model to analyze q1_10_targeted\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Add path for utils\n",
        "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))\n",
        "from utils import data_loader\n",
        "\n",
        "def get_user_ratings(df, user_id):\n",
        "    user_df = df[df['user'] == user_id]\n",
        "    return dict(zip(user_df['item'], user_df['rating']))\n",
        "\n",
        "def main():\n",
        "    print(\"Loading data...\")\n",
        "    df = data_loader.get_preprocessed_dataset()\n",
        "    \n",
        "    # Target Users and their known Top Raw Neighbors (from output_case_study_1.txt)\n",
        "    # We use the neighbors found in Step 2 (Raw Cosine) as they are the most relevant for this \"trust\" analysis\n",
        "    targets_and_neighbors = {\n",
        "        134471: [131078, 131084, 98491, 223, 66017],\n",
        "        27768: [8629, 16611, 20630, 217, 41956],\n",
        "        16157: [5285, 49306, 17495, 50194, 49260]\n",
        "    }\n",
        "    \n",
        "    print(\"\\n10. Trust Analysis (Common vs More Items) for Top Neighbors:\")\n",
        "    \n",
        "    for target_user, neighbors in targets_and_neighbors.items():\n",
        "        print(f\"\\nTarget User: {target_user}\")\n",
        "        target_ratings = get_user_ratings(df, target_user)\n",
        "        target_items = set(target_ratings.keys())\n",
        "        print(f\"  Target Items Count: {len(target_items)}\")\n",
        "        \n",
        "        for neighbor_id in neighbors:\n",
        "            neighbor_ratings = get_user_ratings(df, neighbor_id)\n",
        "            neighbor_items = set(neighbor_ratings.keys())\n",
        "            \n",
        "            common = target_items & neighbor_items\n",
        "            \n",
        "            is_subset = len(neighbor_items) == len(common)\n",
        "            \n",
        "            print(f\"  Neighbor {neighbor_id}:\")\n",
        "            print(f\"    Total Items Rated: {len(neighbor_items)}\")\n",
        "            print(f\"    Common Items: {len(common)}\")\n",
        "            print(f\"    Is Subset (Rated ONLY common)? {is_subset}\")\n",
        "            \n",
        "            if is_subset:\n",
        "                print(\"    -> SUBSET NEIGHBOR (Trust Issue: High similarity based on scant evidence)\")\n",
        "            else:\n",
        "                extra = len(neighbor_items) - len(common)\n",
        "                print(f\"    -> SUPERSET NEIGHBOR (Rated {extra} additional items)\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
