{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e65c58a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f4c2540",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH= 'C:/Users/Nour/Documents/VSCODE/IRS/irs_ass/dataset/Dianping_SocialRec_2015/rating.txt'\n",
    "RESULTS_DIR = 'C:/Users/Nour/Documents/VSCODE/IRS/irs_ass/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60f4e44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59708</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-06-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3781</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2009-12-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120358</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55553</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20837</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-03-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user  item  rating        date\n",
       "0   59708     0       3  2012-06-16\n",
       "1    3781     1       4  2009-12-24\n",
       "2  120358     2       4  2010-08-06\n",
       "3   55553     3       5  2013-07-28\n",
       "4   20837     4       4  2012-03-10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['user', 'item', 'rating', 'date']\n",
    "\n",
    "# Read the rating.txt file into a DataFrame\n",
    "df = pd.read_csv(DATASET_PATH, sep='|', names=column_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "649b3c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing...\n"
     ]
    }
   ],
   "source": [
    "print(\"Preprocessing...\")\n",
    "# Drop timestamp\n",
    "df = df.drop(columns=['date'])\n",
    "df = df[df['rating'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fe0f53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Calculate number of ratings for each user (n_u)\n",
    "user_counts = df.groupby('user')['rating'].count().rename('n_u')\n",
    "user_counts.to_csv(os.path.join(RESULTS_DIR, 'n_u.csv'), header=True)\n",
    "\n",
    "# 4. Calculate number of ratings for each item (n_i)\n",
    "item_counts = df.groupby('item')['rating'].count().rename('n_i')\n",
    "item_counts.to_csv(os.path.join(RESULTS_DIR, 'n_i.csv'), header=True)\n",
    "\n",
    "# 5. Compute average ratings per user (r_u_bar)\n",
    "user_means = df.groupby('user')['rating'].mean().rename('r_u_bar')\n",
    "user_means.to_csv(os.path.join(RESULTS_DIR, 'r_u.csv'), header=True)\n",
    "\n",
    "# 6. Compute average ratings per item (r_i_bar)\n",
    "item_means = df.groupby('item')['rating'].mean().rename('r_i_bar')\n",
    "item_means.to_csv(os.path.join(RESULTS_DIR, 'r_i.csv'), header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fb6fb7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5960</td>\n",
       "      <td>5960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>5390</td>\n",
       "      <td>5390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>5009</td>\n",
       "      <td>5009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>4610</td>\n",
       "      <td>4610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>4332</td>\n",
       "      <td>4332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6192</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10896</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10903</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10906</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11122</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11123 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user  rating\n",
       "item               \n",
       "41     5960    5960\n",
       "507    5390    5390\n",
       "581    5009    5009\n",
       "66     4610    4610\n",
       "1022   4332    4332\n",
       "...     ...     ...\n",
       "6192      1       1\n",
       "10896     1       1\n",
       "10903     1       1\n",
       "10906     1       1\n",
       "11122     1       1\n",
       "\n",
       "[11123 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('item').count().sort_values(by='rating', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17a1ff17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to results/long_tail_plot.png\n"
     ]
    }
   ],
   "source": [
    "# 7. Ascendingly order the total number of ratings per item and plot the distribution per item.\n",
    "sorted_item_counts = item_counts.sort_values(ascending=True)\n",
    "# Correct (Ascending)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Reset index to get a range for x-axis (0 to n_items) representing the items\n",
    "plt.plot(range(len(sorted_item_counts)), sorted_item_counts.values)\n",
    "plt.xlabel('Items (sorted by popularity)')\n",
    "plt.ylabel('Number of Ratings')\n",
    "plt.title('Distribution of Ratings per Item (Ascending)')\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'long_tail_plot.png'))\n",
    "plt.close()\n",
    "print(\"Plot saved to results/long_tail_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c526c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of products per group:\n",
      "r_i_bar\n",
      "G1        0\n",
      "G2        0\n",
      "G3        0\n",
      "G4        9\n",
      "G5        2\n",
      "G6       26\n",
      "G7       69\n",
      "G8      486\n",
      "G9     2646\n",
      "G10    7885\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "max_rating = 5\n",
    "# Define bin edges as percentages of max_rating\n",
    "bin_percentages = [0, 0.01, 0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 1.00]\n",
    "bins = [p * max_rating for p in bin_percentages]\n",
    "labels = ['G1', 'G2', 'G3', 'G4', 'G5', 'G6', 'G7', 'G8', 'G9', 'G10']\n",
    "\n",
    "# Use pd.cut to bin the item means\n",
    "# include_lowest=True ensures that the first bin includes the left edge (0)\n",
    "item_groups = pd.cut(item_means, bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# Count number of products in each group\n",
    "group_counts = item_groups.value_counts().sort_index()\n",
    "\n",
    "print(\"\\nNumber of products per group:\")\n",
    "print(group_counts)\n",
    "group_counts.to_csv(os.path.join(RESULTS_DIR, 'group_counts.csv'), header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6dd9c7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total ratings per group (sorted):\n",
      "group\n",
      "G1           0\n",
      "G2           0\n",
      "G3           0\n",
      "G5           6\n",
      "G4          14\n",
      "G6         161\n",
      "G7        1008\n",
      "G8       15847\n",
      "G9      343083\n",
      "G10    1789536\n",
      "Name: n_i, dtype: int64\n",
      "Plot saved to results/ratings_per_group.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nour\\AppData\\Local\\Temp\\ipykernel_22380\\2554476892.py:5: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  group_ratings = item_data.groupby('group')['n_i'].sum()\n"
     ]
    }
   ],
   "source": [
    "# 9. Compute the total number of ratings in each group and order them ascendingly\n",
    "# item_counts has the number of ratings per item, item_groups has the group assignment\n",
    "item_data = pd.DataFrame({'group': item_groups, 'n_i': item_counts})\n",
    "# Sum n_i for each group\n",
    "group_ratings = item_data.groupby('group')['n_i'].sum()\n",
    "\n",
    "# Order them ascendingly (by total ratings)\n",
    "sorted_group_ratings = group_ratings.sort_values(ascending=True)\n",
    "\n",
    "print(\"\\nTotal ratings per group (sorted):\")\n",
    "print(sorted_group_ratings)\n",
    "sorted_group_ratings.to_csv(os.path.join(RESULTS_DIR, 'group_ratings_sorted.csv'), header=True)\n",
    "\n",
    "# Plot distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sorted_group_ratings.plot(kind='bar')\n",
    "plt.xlabel('Groups (sorted by total ratings)')\n",
    "plt.ylabel('Total Number of Ratings')\n",
    "plt.title('Distribution of Ratings per Group (Ascending)')\n",
    "plt.grid(axis='y')\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'ratings_per_group.png'))\n",
    "plt.close()\n",
    "print(\"Plot saved to results/ratings_per_group.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9e9914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total ratings per group (unsorted):\n",
      "group\n",
      "G1           0\n",
      "G2           0\n",
      "G3           0\n",
      "G4          14\n",
      "G5           6\n",
      "G6         161\n",
      "G7        1008\n",
      "G8       15847\n",
      "G9      343083\n",
      "G10    1789536\n",
      "Name: n_i, dtype: int64\n",
      "Plot saved to results/ratings_per_group_unsorted.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nour\\AppData\\Local\\Temp\\ipykernel_22380\\2479050952.py:5: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  group_ratings = item_data.groupby('group')['n_i'].sum()\n"
     ]
    }
   ],
   "source": [
    "# 9. Compute the total number of ratings in each group before sorting\n",
    "# item_counts has the number of ratings per item, item_groups has the group assignment\n",
    "item_data = pd.DataFrame({'group': item_groups, 'n_i': item_counts})\n",
    "# Sum n_i for each group\n",
    "group_ratings = item_data.groupby('group')['n_i'].sum()\n",
    "\n",
    "print(\"\\nTotal ratings per group (unsorted):\")\n",
    "print(group_ratings)\n",
    "group_ratings.to_csv(os.path.join(RESULTS_DIR, 'group_ratings_unsorted.csv'), header=True)\n",
    "\n",
    "# Plot distribution BEFORE sorting\n",
    "plt.figure(figsize=(10, 6))\n",
    "group_ratings.plot(kind='bar')  # Changed from sorted_group_ratings to group_ratings\n",
    "plt.xlabel('Groups (unsorted)')\n",
    "plt.ylabel('Total Number of Ratings')\n",
    "plt.title('Distribution of Ratings per Group (unsorted)')\n",
    "plt.grid(axis='y')\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'ratings_per_group_unsorted.png'))\n",
    "plt.close()\n",
    "print(\"Plot saved to results/ratings_per_group_unsorted.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d62e18",
   "metadata": {},
   "source": [
    "# 13 & 14: Target Selection and Co-rating Analysis\n",
    "\n",
    "## Cell 13: Target User and Item Selection\n",
    "\n",
    "This cell selects representative users and items for testing the recommender system based on different activity and popularity levels.\n",
    "\n",
    "### Part A: Selecting 3 Target Users (U1, U2, U3)\n",
    "\n",
    "**Objective:** Identify users with varying activity levels based on the number of items they have rated.\n",
    "\n",
    "**Threshold Calculation:**\n",
    "```python\n",
    "n_items = df['item'].nunique()  # Total unique items = 11,123\n",
    "t1 = 0.02 * n_items  # 2% threshold = 222.46 items\n",
    "t2 = 0.05 * n_items  # 5% threshold = 556.15 items\n",
    "t3 = 0.10 * n_items  # 10% threshold = 1,112.3 items\n",
    "```\n",
    "\n",
    "**User Categories:**\n",
    "- **U1 candidates**: Users who rated ≤ 2% of items (≤ 222 items) → Low activity users\n",
    "- **U2 candidates**: Users who rated > 2% and ≤ 5% of items (223-556 items) → Medium activity users\n",
    "- **U3 candidates**: Users who rated > 5% and ≤ 10% of items (557-1,112 items) → High activity users\n",
    "\n",
    "**Selection Method:**\n",
    "The code uses random sampling with a fixed seed (`random_state=42`) to ensure reproducibility. One user is randomly selected from each category.\n",
    "\n",
    "**Selected Target Users:**\n",
    "- **U1 = 134471** (rated 11 items) - Sparse user profile representing casual users\n",
    "- **U2 = 27768** (rated 293 items) - Moderate user profile representing regular users\n",
    "- **U3 = 16157** (rated 626 items) - Active user profile representing power users\n",
    "\n",
    "---\n",
    "\n",
    "### Part B: Selecting 2 Target Items (I1, I2)\n",
    "\n",
    "**Objective:** Identify items with moderate popularity to test recommendation algorithms on neither extremely popular nor extremely obscure items.\n",
    "\n",
    "**Threshold Calculation:**\n",
    "```python\n",
    "n_users = df['user'].nunique()  # Total unique users = 147,914\n",
    "it1 = 0.005 * n_users  # 0.5% threshold = 739.57 users\n",
    "it2 = 0.01 * n_users   # 1% threshold = 1,479.14 users\n",
    "```\n",
    "\n",
    "**Item Selection Criteria:**\n",
    "Items must be rated by more than 0.5% but ≤ 1% of all users (740-1,479 users). This range represents moderately popular items that are neither blockbusters nor niche products.\n",
    "\n",
    "**Selected Target Items:**\n",
    "- **I1 = 780** (rated by 1,019 users)\n",
    "- **I2 = 2185** (rated by 1,038 users)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b767bf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total items: 11123\n",
      "Selected U1: 134471 (Ratings: 11)\n",
      "Selected U2: 27768 (Ratings: 293)\n",
      "Selected U3: 16157 (Ratings: 626)\n",
      "\n",
      "Total users: 147914\n",
      "Item Thresholds: IT1=739.57, IT2=1479.14\n",
      "\n",
      "Selected Target Items (Popularity 1-2% of users):\n",
      "I1: 780 (Ratings: 1019)\n",
      "I2: 2185 (Ratings: 1038)\n"
     ]
    }
   ],
   "source": [
    "# 11. select 3 target users\n",
    "\n",
    "n_items = df['item'].nunique()  # Total unique items = 11,123\n",
    "t1 = 0.02 * n_items  # 2% threshold = 222.46 items\n",
    "t2 = 0.05 * n_items  # 5% threshold = 556.15 items\n",
    "t3 = 0.10 * n_items  # 10% threshold = 1,112.3 items\n",
    "\n",
    "print(f\"\\nTotal items: {n_items}\")\n",
    "\n",
    "# Filter users\n",
    "u1_candidates = user_counts[user_counts <= t1]\n",
    "u2_candidates = user_counts[(user_counts > t1) & (user_counts <= t2)]\n",
    "u3_candidates = user_counts[(user_counts > t2) & (user_counts <= t3)]\n",
    "\n",
    "# Select one random user from each group if available\n",
    "np.random.seed(42) # For reproducibility\n",
    "\n",
    "def get_random_user(candidates, label):\n",
    "    if not candidates.empty:\n",
    "        user = candidates.sample(n=1, random_state=42).index[0]\n",
    "        print(f\"Selected {label}: {user} (Ratings: {candidates[user]})\")\n",
    "        return user\n",
    "    else:\n",
    "        print(f\"No candidates for {label}\")\n",
    "        return None\n",
    "\n",
    "u1 = get_random_user(u1_candidates, \"U1\")\n",
    "u2 = get_random_user(u2_candidates, \"U2\")\n",
    "u3 = get_random_user(u3_candidates, \"U3\")\n",
    "\n",
    "\n",
    "# 12. Select two target items: items with ratings between 0.5% and 1% of users\n",
    "n_users = df['user'].nunique()\n",
    "it1 = 0.005 * n_users\n",
    "it2 = 0.01 * n_users\n",
    "\n",
    "print(f\"\\nTotal users: {n_users}\")\n",
    "print(f\"Item Thresholds: IT1={it1:.2f}, IT2={it2:.2f}\")\n",
    "\n",
    "# Filter items based on popularity (n_i)\n",
    "# item_counts contains n_i for each item\n",
    "target_item_candidates = item_counts[(item_counts > it1) & (item_counts <= it2)]\n",
    "\n",
    "if not target_item_candidates.empty:\n",
    "    # Select two random items\n",
    "    if len(target_item_candidates) >= 2:\n",
    "        selected_items = target_item_candidates.sample(n=2, random_state=42)\n",
    "        i1 = selected_items.index[0]\n",
    "        i2 = selected_items.index[1]\n",
    "        print(f\"\\nSelected Target Items (Popularity 1-2% of users):\")\n",
    "        print(f\"I1: {i1} (Ratings: {selected_items[i1]})\")\n",
    "        print(f\"I2: {i2} (Ratings: {selected_items[i2]})\")\n",
    "    else:\n",
    "        print(\"Not enough items in the 1-2% popularity range to select 2.\")\n",
    "        # Fallback or handle appropriately - for now just take what we have or None\n",
    "        i1 = target_item_candidates.index[0]\n",
    "        i2 = None\n",
    "        print(f\"I1: {i1}\")\n",
    "else:\n",
    "    print(\"No items found in the 1-2% popularity range.\")\n",
    "    i1 = None\n",
    "    i2 = None\n",
    "\n",
    "# Save selected targets to a file for reference\n",
    "if not os.path.exists(os.path.join(RESULTS_DIR, 'target_users.txt')):\n",
    "    with open(os.path.join(RESULTS_DIR, 'target_users.txt'), 'w') as f:\n",
    "        f.write(f\"{u1}\\n\")\n",
    "        f.write(f\"{u2}\\n\")\n",
    "        f.write(f\"{u3}\\n\")\n",
    "\n",
    "if not os.path.exists(os.path.join(RESULTS_DIR, 'target_items.txt')):\n",
    "    with open(os.path.join(RESULTS_DIR, 'target_items.txt'), 'w') as f:\n",
    "        f.write(f\"{i1}\\n\")\n",
    "        f.write(f\"{i2}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc295ee",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Cell 14: Co-rating Analysis and Beta Threshold Determination\n",
    "\n",
    "This cell performs collaborative filtering analysis by computing overlap metrics between users and items, which are essential for neighborhood-based recommendation algorithms.\n",
    "\n",
    "### Data Preparation\n",
    "\n",
    "**Efficient Lookup Structures:**\n",
    "```python\n",
    "user_items = df.groupby('user')['item'].apply(set).to_dict()\n",
    "# Example: {134471: {item1, item2, item3, ...}, ...}\n",
    "\n",
    "item_users = df.groupby('item')['user'].apply(set).to_dict()\n",
    "# Example: {780: {user1, user2, user3, ...}, ...}\n",
    "```\n",
    "\n",
    "These dictionaries use sets for fast intersection operations when finding common items or users.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 13: Co-rating Users and Co-rated Items Analysis\n",
    "\n",
    "#### Target Users Analysis\n",
    "\n",
    "For each target user, the algorithm counts how many other users have rated at least one common item.\n",
    "\n",
    "**Algorithm:**\n",
    "```python\n",
    "for u_target in target_users:\n",
    "    target_items_set = user_items.get(u_target, set())  # Items rated by target user\n",
    "    no_common_users = 0\n",
    "    \n",
    "    for u_other, other_items_set in user_items.items():\n",
    "        if u_other == u_target:\n",
    "            continue\n",
    "        \n",
    "        intersection_size = len(target_items_set.intersection(other_items_set))\n",
    "        \n",
    "        if intersection_size > 0:\n",
    "            no_common_users += 1\n",
    "```\n",
    "\n",
    "**Results:**\n",
    "- **U1 (user 134471)**: 9,747 co-rating users\n",
    "  - U1 rated 11 items\n",
    "  - 9,747 other users have rated at least 1 of those same 11 items\n",
    "  - These represent potential neighbors for user-based collaborative filtering\n",
    "\n",
    "- **U2 (user 27768)**: 62,863 co-rating users\n",
    "  - U2 rated 293 items\n",
    "  - 62,863 other users share at least 1 common item\n",
    "  - Higher activity leads to more potential neighbors\n",
    "\n",
    "- **U3 (user 16157)**: 77,177 co-rating users\n",
    "  - U3 rated 626 items\n",
    "  - 77,177 other users share at least 1 common item\n",
    "  - The most active user has the largest neighborhood\n",
    "\n",
    "---\n",
    "\n",
    "#### Target Items Analysis\n",
    "\n",
    "For each target item, the algorithm counts how many other items share at least one common user (i.e., items that have been co-rated by at least one user).\n",
    "\n",
    "**Algorithm:**\n",
    "```python\n",
    "for i_target in target_items_list:\n",
    "    target_users_set = item_users.get(i_target, set())  # Users who rated target item\n",
    "    no_corated_items = 0\n",
    "    \n",
    "    for i_other, other_users_set in item_users.items():\n",
    "        if i_other == i_target:\n",
    "            continue\n",
    "        \n",
    "        intersection_size = len(target_users_set.intersection(other_users_set))\n",
    "        \n",
    "        if intersection_size > 0:\n",
    "            no_corated_items += 1\n",
    "```\n",
    "\n",
    "**Results:**\n",
    "- **I1 (item 780)**: 7,733 co-rated items\n",
    "  - Out of 11,123 total items, approximately 69.5% have been co-rated with item 780\n",
    "  - This indicates strong connectivity in the item-item network\n",
    "\n",
    "- **I2 (item 2185)**: 7,379 co-rated items\n",
    "  - Approximately 66.3% of all items share at least one common user with item 2185\n",
    "  - Similar connectivity pattern to I1\n",
    "\n",
    "**Interpretation:** The high percentage of co-rated items demonstrates that the dataset has good connectivity, which is favorable for item-based collaborative filtering algorithms.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 14: Beta Threshold Determination\n",
    "\n",
    "**Objective:** Determine β, the number of users who have co-rated at least 30% of items with each target user. This metric identifies high-quality neighbors with significant overlap.\n",
    "\n",
    "**Algorithm:**\n",
    "```python\n",
    "threshold_30 = 0.30 * n_target_ratings  # 30% of target user's rated items\n",
    "\n",
    "for u_other, other_items_set in user_items.items():\n",
    "    intersection_size = len(target_items_set.intersection(other_items_set))\n",
    "    \n",
    "    if intersection_size >= threshold_30:\n",
    "        beta_count += 1\n",
    "```\n",
    "\n",
    "**Results:**\n",
    "\n",
    "- **U1 (11 ratings)**: β = 15 users\n",
    "  - Threshold: 0.30 × 11 = 3.3 items\n",
    "  - 15 users have rated at least 4 of the same items as U1\n",
    "  - These users are strong candidates for neighborhood-based recommendations\n",
    "\n",
    "- **U2 (293 ratings)**: β = 0 users\n",
    "  - Threshold: 0.30 × 293 = 87.9 items\n",
    "  - No other user has rated at least 88 of the same items as U2\n",
    "  - The 30% threshold is too strict for moderately active users\n",
    "\n",
    "- **U3 (626 ratings)**: β = 0 users\n",
    "  - Threshold: 0.30 × 626 = 187.8 items\n",
    "  - No other user has rated at least 188 of the same items as U3\n",
    "  - The 30% threshold is extremely strict for highly active users\n",
    "\n",
    "**Key Insight:** The 30% overlap threshold works well for sparse users (U1) but becomes impractical for active users (U2, U3). This suggests that adaptive thresholds or alternative similarity metrics may be needed for users with different activity levels in the recommendation system.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary and Implications\n",
    "\n",
    "These two cells establish the foundation for collaborative filtering by:\n",
    "\n",
    "1. **Selecting diverse test cases** across different user activity levels (sparse, moderate, active) and item popularity levels (moderately popular)\n",
    "\n",
    "2. **Measuring neighborhood sizes** for collaborative filtering:\n",
    "   - **Co-rating users** → Used for user-based collaborative filtering (finding similar users)\n",
    "   - **Co-rated items** → Used for item-based collaborative filtering (finding similar items)\n",
    "\n",
    "3. **Identifying quality thresholds** through the β metric, which reveals that:\n",
    "   - Sparse users have small but high-quality neighborhoods\n",
    "   - Active users have large neighborhoods but require relaxed similarity thresholds\n",
    "\n",
    "These metrics are crucial for understanding data sparsity and connectivity, which directly impact the performance and feasibility of different recommendation algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc351c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Steps 13 & 14...\n",
      "\n",
      "--- Target Users Analysis ---\n",
      "User 134471: Ratings=11, No_common_users=9747, Beta (>=30% overlap)=15\n",
      "User 27768: Ratings=293, No_common_users=62863, Beta (>=30% overlap)=0\n",
      "User 16157: Ratings=626, No_common_users=77177, Beta (>=30% overlap)=0\n",
      "\n",
      "--- Target Items Analysis ---\n",
      "Item 780: No_coRated_items=7733\n",
      "Item 2185: No_coRated_items=7379\n"
     ]
    }
   ],
   "source": [
    "# 13. Count the number of co-rating users and co-rated items\n",
    "# 14. Determine the threshold beta\n",
    "\n",
    "print(\"\\nStarting Steps 13 & 14...\")\n",
    "\n",
    "# Precompute user_items and item_users maps for efficiency\n",
    "# Group by user and collect items into a set\n",
    "user_items = df.groupby('user')['item'].apply(set).to_dict()\n",
    "# Group by item and collect users into a set\n",
    "item_users = df.groupby('item')['user'].apply(set).to_dict()\n",
    "\n",
    "target_users = [u for u in [u1, u2, u3] if u is not None]\n",
    "target_items_list = [i for i in [i1, i2] if i is not None]\n",
    "\n",
    "results_13_14 = []\n",
    "\n",
    "print(\"\\n--- Target Users Analysis ---\")\n",
    "for u_target in target_users:\n",
    "    target_items_set = user_items.get(u_target, set())\n",
    "    n_target_ratings = len(target_items_set)\n",
    "    \n",
    "    no_common_users = 0\n",
    "    beta_count = 0\n",
    "    threshold_30 = 0.30 * n_target_ratings\n",
    "    \n",
    "    # Iterate over all other users\n",
    "    for u_other, other_items_set in user_items.items():\n",
    "        if u_other == u_target:\n",
    "            continue\n",
    "            \n",
    "        # Intersection size\n",
    "        intersection_size = len(target_items_set.intersection(other_items_set))\n",
    "        \n",
    "        if intersection_size > 0:\n",
    "            no_common_users += 1\n",
    "            \n",
    "        # Step 14 check\n",
    "        if intersection_size >= threshold_30:\n",
    "            beta_count += 1\n",
    "            \n",
    "    print(f\"User {u_target}: Ratings={n_target_ratings}, No_common_users={no_common_users}, Beta (>=30% overlap)={beta_count}\")\n",
    "    results_13_14.append({'Type': 'User', 'ID': u_target, 'Count': no_common_users, 'Beta': beta_count})\n",
    "\n",
    "print(\"\\n--- Target Items Analysis ---\")\n",
    "for i_target in target_items_list:\n",
    "    target_users_set = item_users.get(i_target, set())\n",
    "    \n",
    "    no_corated_items = 0\n",
    "    \n",
    "    # Iterate over all other items\n",
    "    for i_other, other_users_set in item_users.items():\n",
    "        if i_other == i_target:\n",
    "            continue\n",
    "            \n",
    "        intersection_size = len(target_users_set.intersection(other_users_set))\n",
    "        \n",
    "        if intersection_size > 0:\n",
    "            no_corated_items += 1\n",
    "            \n",
    "    print(f\"Item {i_target}: No_coRated_items={no_corated_items}\")\n",
    "    results_13_14.append({'Type': 'Item', 'ID': i_target, 'Count': no_corated_items, 'Beta': 'N/A'})\n",
    "\n",
    "# Save results\n",
    "pd.DataFrame(results_13_14).to_csv(os.path.join(RESULTS_DIR, 'results_13_14.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfd3291",
   "metadata": {},
   "source": [
    "# Section 1.16 --> Matrix Sparsity, Rating Bias, and Long-Tail Problems\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This analysis evaluates the Dianping Social Recommendation 2015 dataset by examining three critical challenges in recommender systems: **matrix sparsity**, **rating bias**, and **long-tail distribution**. By comparing results from Steps 13 & 14 (co-rating analysis) with earlier statistical findings, we provide comprehensive insights into the dataset's characteristics and their implications for recommendation algorithms.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Matrix Sparsity Analysis\n",
    "\n",
    "### 1.1 Sparsity Calculation\n",
    "\n",
    "**Dataset Dimensions:**\n",
    "- Total users: 147,914\n",
    "- Total items: 11,123\n",
    "- Total ratings: 2,149,655\n",
    "- Potential matrix size: 147,914 × 11,123 = 1,645,408,322 cells\n",
    "\n",
    "**Sparsity Metric:**\n",
    "```\n",
    "Sparsity = 1 - (Actual Ratings / Potential Ratings)\n",
    "Sparsity = 1 - (2,149,655 / 1,645,408,322)\n",
    "Sparsity = 1 - 0.001306\n",
    "Sparsity = 99.87%\n",
    "```\n",
    "\n",
    "**Interpretation:** The user-item matrix is **99.87% sparse**, meaning only 0.13% of possible user-item interactions have been observed. This extreme sparsity is a fundamental challenge for collaborative filtering algorithms.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.2 Evidence from Steps 13 & 14: User-Level Sparsity\n",
    "\n",
    "The co-rating analysis reveals how sparsity manifests differently across user activity levels:\n",
    "\n",
    "#### **U1 (Low Activity User - 11 ratings):**\n",
    "- Rated only 0.099% of all items (11 / 11,123)\n",
    "- **Co-rating users:** 9,747 (6.6% of all users)\n",
    "- **Beta (≥30% overlap):** 15 users (0.01% of all users)\n",
    "\n",
    "**Insight:** Despite extreme individual sparsity, U1 still has nearly 10,000 potential neighbors. However, only 15 users meet the 30% overlap threshold, indicating that while many users share *some* items, very few share *enough* items for high-confidence similarity calculations.\n",
    "\n",
    "#### **U2 (Medium Activity User - 293 ratings):**\n",
    "- Rated 2.6% of all items (293 / 11,123)\n",
    "- **Co-rating users:** 62,863 (42.5% of all users)\n",
    "- **Beta (≥30% overlap):** 0 users\n",
    "\n",
    "**Insight:** U2's moderate activity increases neighborhood size dramatically (6.4× more than U1), but paradoxically, **no users** meet the 30% threshold (88 common items). This reveals a critical sparsity problem: as users rate more items, the probability of finding users with proportionally similar coverage decreases.\n",
    "\n",
    "#### **U3 (High Activity User - 626 ratings):**\n",
    "- Rated 5.6% of all items (626 / 11,123)\n",
    "- **Co-rating users:** 77,177 (52.2% of all users)\n",
    "- **Beta (≥30% overlap):** 0 users\n",
    "\n",
    "**Insight:** U3 has the largest neighborhood (over half of all users), yet still **zero users** with ≥30% overlap (188 common items). This demonstrates the **paradox of active users**: they have more data but suffer from unique taste profiles that are harder to match.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.3 Item-Level Connectivity\n",
    "\n",
    "#### **I1 (Item 780 - 1,019 ratings):**\n",
    "- Rated by 0.69% of all users\n",
    "- **Co-rated items:** 7,733 (69.5% of all items)\n",
    "\n",
    "#### **I2 (Item 2185 - 1,038 ratings):**\n",
    "- Rated by 0.70% of all users\n",
    "- **Co-rated items:** 7,379 (66.3% of all items)\n",
    "\n",
    "**Insight:** Despite being rated by less than 1% of users, these moderately popular items share common users with ~70% of the catalog. This indicates **better connectivity at the item level** compared to the user level, suggesting that **item-based collaborative filtering** may be more robust than user-based approaches for this dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.4 Sparsity Implications\n",
    "\n",
    "**Comparison Summary:**\n",
    "\n",
    "| Metric | U1 (Sparse) | U2 (Moderate) | U3 (Active) | Items (I1, I2) |\n",
    "|--------|-------------|---------------|-------------|----------------|\n",
    "| Coverage | 0.099% | 2.6% | 5.6% | 0.69% |\n",
    "| Neighborhood Size | 9,747 | 62,863 | 77,177 | ~7,500 |\n",
    "| High-Quality Neighbors (β) | 15 | 0 | 0 | N/A |\n",
    "| Connectivity | Low | Medium | High | Very High |\n",
    "\n",
    "**Key Findings:**\n",
    "1. **User-based CF challenges:** The 30% overlap threshold is only viable for very sparse users (U1), making traditional user-based similarity metrics impractical for most users.\n",
    "2. **Item-based CF advantage:** Items show 66-70% connectivity, significantly better than user connectivity (6.6-52.2%).\n",
    "3. **Adaptive thresholds needed:** Fixed overlap percentages fail across different activity levels; algorithms must adapt thresholds based on user profile density.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Rating Bias Analysis\n",
    "\n",
    "### 2.1 Item Rating Distribution (from Step 8)\n",
    "\n",
    "Items were grouped by average rating into 10 categories (G1-G10):\n",
    "\n",
    "| Group | Rating Range | # Items | % of Catalog | Total Ratings | % of All Ratings |\n",
    "|-------|--------------|---------|--------------|---------------|------------------|\n",
    "| G1 | 0.00-0.05 | 0 | 0.0% | 0 | 0.0% |\n",
    "| G2 | 0.05-0.25 | 0 | 0.0% | 0 | 0.0% |\n",
    "| G3 | 0.25-0.50 | 0 | 0.0% | 0 | 0.0% |\n",
    "| G4 | 0.50-1.00 | 9 | 0.08% | 14 | 0.0007% |\n",
    "| G5 | 1.00-1.50 | 2 | 0.02% | 6 | 0.0003% |\n",
    "| G6 | 1.50-2.00 | 26 | 0.23% | 161 | 0.0075% |\n",
    "| G7 | 2.00-2.50 | 69 | 0.62% | 1,008 | 0.047% |\n",
    "| G8 | 2.50-3.00 | 486 | 4.37% | 15,847 | 0.737% |\n",
    "| G9 | 3.00-3.50 | 2,646 | 23.8% | 343,083 | 15.96% |\n",
    "| **G10** | **3.50-5.00** | **7,885** | **70.9%** | **1,789,536** | **83.25%** |\n",
    "\n",
    "### 2.2 Extreme Positive Bias\n",
    "\n",
    "**Critical Observation:** \n",
    "- **70.9% of all items** have average ratings between 3.5-5.0 stars\n",
    "- **83.25% of all ratings** are concentrated in this high-rating group (G10)\n",
    "- Only 11 items (0.1%) have average ratings below 2.0 stars\n",
    "\n",
    "**Interpretation:** The dataset exhibits **severe positive rating bias**, where users predominantly rate items they like (3.5+ stars) and rarely rate items they dislike. This is a classic example of **selection bias** in implicit feedback systems.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.3 Comparison with Steps 13 & 14\n",
    "\n",
    "#### **Impact on User Similarity:**\n",
    "\n",
    "The positive bias affects similarity calculations:\n",
    "\n",
    "- **U1 (avg rating unknown):** With only 11 ratings, U1's profile is too sparse to exhibit strong bias patterns, but the 15 users with ≥30% overlap likely share similar positive preferences.\n",
    "\n",
    "- **U2 & U3 (293 and 626 ratings):** These users have rated enough items to reflect the dataset's positive bias. The fact that **zero users** meet the 30% threshold suggests that even among positively-biased users, individual taste variations prevent strong overlap.\n",
    "\n",
    "#### **Impact on Item Similarity:**\n",
    "\n",
    "- **I1 & I2 (moderately popular items):** Both items have 1,000+ ratings and likely fall in G9 or G10 (high average ratings). Their 66-70% co-rating connectivity indicates that users who rate these items also rate many other popular, highly-rated items, reinforcing the positive bias.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.4 Rating Bias Implications\n",
    "\n",
    "**Consequences for Recommender Systems:**\n",
    "\n",
    "1. **Reduced discriminative power:** When most items are rated 3.5-5.0, it's harder to distinguish user preferences. A 4.0 rating might mean \"good\" for one user but \"mediocre\" for another.\n",
    "\n",
    "2. **Cold-start amplification:** New items without ratings are assumed to be average (~3.5), but this may overestimate their quality if they would naturally fall in lower groups.\n",
    "\n",
    "3. **Popularity reinforcement:** High-rated items (G10) receive 83% of ratings, creating a feedback loop where popular items get more exposure and more positive ratings.\n",
    "\n",
    "4. **Comparison with Step 14 β-threshold:** The strict 30% overlap requirement is even harder to meet when users rate different subsets of the same positively-biased item pool, explaining why U2 and U3 have β=0.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Long-Tail Distribution Analysis\n",
    "\n",
    "### 3.1 Item Popularity Distribution (from Step 7)\n",
    "\n",
    "The long-tail plot reveals extreme popularity concentration:\n",
    "\n",
    "**Top Items:**\n",
    "- Item 41: 5,960 ratings (most popular)\n",
    "- Item 507: 5,390 ratings\n",
    "- Item 581: 5,009 ratings\n",
    "\n",
    "**Tail Items:**\n",
    "- Thousands of items with only 1 rating\n",
    "- Examples: Items 6192, 10896, 10903, 10906, 11122 (each with 1 rating)\n",
    "\n",
    "**Distribution Characteristics:**\n",
    "- **Head (top 1%):** ~111 items receive disproportionate attention\n",
    "- **Torso (middle 20%):** ~2,200 items have moderate ratings\n",
    "- **Tail (bottom 79%):** ~8,800 items are rarely rated\n",
    "\n",
    "---\n",
    "\n",
    "### 3.2 Quantitative Evidence from Steps 13 & 14\n",
    "\n",
    "#### **Target Item Selection (Step 12):**\n",
    "- **I1 & I2** were selected from the **0.5-1% popularity range** (740-1,479 ratings)\n",
    "- These items are in the **upper torso** of the distribution, not the head or tail\n",
    "\n",
    "#### **Co-rating Connectivity:**\n",
    "- **I1 (1,019 ratings):** 7,733 co-rated items (69.5%)\n",
    "- **I2 (1,038 ratings):** 7,379 co-rated items (66.3%)\n",
    "\n",
    "**Insight:** Even items in the upper torso have strong connectivity with the majority of the catalog. This suggests that:\n",
    "1. **Head items** (5,000+ ratings) likely have 90%+ co-rating connectivity\n",
    "2. **Tail items** (1-10 ratings) have minimal connectivity, making them hard to recommend\n",
    "\n",
    "---\n",
    "\n",
    "### 3.3 Long-Tail Impact on User Neighborhoods\n",
    "\n",
    "Comparing user neighborhoods with item popularity:\n",
    "\n",
    "| User | Ratings | Co-rating Users | Likely Item Mix |\n",
    "|------|---------|-----------------|-----------------|\n",
    "| U1 | 11 | 9,747 | Likely rated popular items (head/torso) to have 9,747 overlaps |\n",
    "| U2 | 293 | 62,863 | Mix of head, torso, and some tail items |\n",
    "| U3 | 626 | 77,177 | Broader mix including more tail items |\n",
    "\n",
    "**Insight:** U1's small profile (11 items) still yields 9,747 co-rating users, suggesting these 11 items are likely **popular items from the head/torso**. If U1 had rated 11 tail items, the co-rating count would be drastically lower.\n",
    "\n",
    "**Implication:** User-based CF is biased toward users who rate popular items, as they have more neighbors. Users who explore niche (tail) items suffer from isolation.\n",
    "\n",
    "---\n",
    "\n",
    "### 3.4 Long-Tail and the β-Threshold Paradox\n",
    "\n",
    "**Why β=0 for U2 and U3:**\n",
    "\n",
    "The long-tail distribution exacerbates the β-threshold problem:\n",
    "\n",
    "1. **U2 (293 ratings):** To meet β, another user must share 88 items. Given the long-tail, the probability that two users independently rate the same 88 items (many of which are in the tail) is extremely low.\n",
    "\n",
    "2. **U3 (626 ratings):** Requires 188 common items. U3 likely rated many tail items (since they're active), but tail items have few raters, making overlap unlikely.\n",
    "\n",
    "**Comparison with I1 & I2:**\n",
    "- Items in the torso (I1, I2) have 1,000+ ratings, meaning 1,000+ users rated them\n",
    "- This creates natural overlap: if two users both rate 100 items, and 20 of those are popular torso items, they'll share those 20\n",
    "- But if U3 rates 626 items including 200 tail items, finding another user who rated the same 200 tail items is nearly impossible\n",
    "\n",
    "---\n",
    "\n",
    "### 3.5 Long-Tail Implications\n",
    "\n",
    "**Key Findings:**\n",
    "\n",
    "1. **Popularity bias in recommendations:** Algorithms will naturally favor head items (5,000+ ratings) because they have the most data and connectivity.\n",
    "\n",
    "2. **Tail item cold-start:** 79% of items in the tail are under-recommended due to sparse data, perpetuating the long-tail problem.\n",
    "\n",
    "3. **User exploration penalty:** Active users (U2, U3) who explore tail items are penalized with β=0 because their profiles are harder to match.\n",
    "\n",
    "4. **Item-based CF resilience:** Items I1 and I2 (torso items) maintain 66-70% connectivity, suggesting item-based CF can bridge the long-tail better than user-based CF.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Integrated Discussion: Comparing Steps 13 & 14 with Overall Dataset\n",
    "\n",
    "### 4.1 The Sparsity-Bias-Long-Tail Nexus\n",
    "\n",
    "The three problems are **interconnected**:\n",
    "\n",
    "1. **Sparsity** (99.87%) means most user-item pairs are unobserved\n",
    "2. **Positive bias** (83% of ratings are 3.5-5.0) reduces the discriminative power of observed ratings\n",
    "3. **Long-tail** (79% of items have few ratings) concentrates observations on a small subset of items\n",
    "\n",
    "**Result:** The dataset has high volume (2.1M ratings) but low information density due to these three factors.\n",
    "\n",
    "---\n",
    "\n",
    "### 4.2 User-Based vs. Item-Based CF: Evidence from Steps 13 & 14\n",
    "\n",
    "| Approach | Connectivity | Quality Threshold (β) | Robustness |\n",
    "|----------|--------------|----------------------|------------|\n",
    "| **User-based CF** | 6.6% - 52.2% | β=0 for active users | **Poor** |\n",
    "| **Item-based CF** | 66-70% | N/A (not computed) | **Good** |\n",
    "\n",
    "**Recommendation:** Item-based collaborative filtering is more suitable for this dataset due to higher connectivity and resilience to sparsity.\n",
    "\n",
    "---\n",
    "\n",
    "### 4.3 Adaptive Strategies for Different User Types\n",
    "\n",
    "Based on Steps 13 & 14 results:\n",
    "\n",
    "#### **For Sparse Users (like U1):**\n",
    "- **Strategy:** User-based CF with β-threshold (15 high-quality neighbors available)\n",
    "- **Rationale:** Small profiles are easier to match, and β=15 provides sufficient neighbors\n",
    "\n",
    "#### **For Moderate Users (like U2):**\n",
    "- **Strategy:** Hybrid approach (item-based CF + content-based filtering)\n",
    "- **Rationale:** β=0 makes user-based CF impractical; item-based CF leverages 66-70% item connectivity\n",
    "\n",
    "#### **For Active Users (like U3):**\n",
    "- **Strategy:** Matrix factorization or deep learning (e.g., neural collaborative filtering)\n",
    "- **Rationale:** Traditional CF fails (β=0); latent factor models can capture complex patterns in 626 ratings\n",
    "\n",
    "---\n",
    "\n",
    "### 4.4 Addressing the Long-Tail Problem\n",
    "\n",
    "**Insights from Item Analysis (I1, I2):**\n",
    "\n",
    "- Moderately popular items (torso) have strong connectivity (66-70%)\n",
    "- Recommendation: Use **item-based CF** to propagate recommendations from torso to tail items\n",
    "- Example: If a user rates I1 (torso item), recommend other items co-rated with I1, including tail items\n",
    "\n",
    "**Tail Item Promotion Strategy:**\n",
    "1. Identify tail items co-rated with popular items (leverage I1/I2's 7,000+ co-rated items)\n",
    "2. Use content-based features to recommend tail items to users with similar preferences\n",
    "3. Implement exploration bonuses (e.g., Thompson Sampling) to occasionally recommend tail items\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Conclusions and Recommendations\n",
    "\n",
    "### 5.1 Key Insights\n",
    "\n",
    "1. **Extreme Sparsity (99.87%):** Only 0.13% of user-item interactions are observed, making traditional CF challenging.\n",
    "\n",
    "2. **User-Based CF Limitations:** The β-threshold analysis (Step 14) reveals that only very sparse users (U1) have high-quality neighbors; active users (U2, U3) have β=0, making user-based CF impractical for most users.\n",
    "\n",
    "3. **Item-Based CF Superiority:** Items show 66-70% connectivity (Step 13), significantly better than user connectivity (6.6-52.2%), making item-based CF more robust.\n",
    "\n",
    "4. **Positive Rating Bias:** 83% of ratings are 3.5-5.0 stars, reducing discriminative power and requiring normalized similarity metrics.\n",
    "\n",
    "5. **Long-Tail Dominance:** 79% of items are in the tail, but the co-rating analysis shows that torso items (I1, I2) can bridge to tail items through shared users.\n",
    "\n",
    "---\n",
    "\n",
    "### 5.2 Algorithmic Recommendations\n",
    "\n",
    "Based on the comparative analysis of Steps 13 & 14 with the overall dataset:\n",
    "\n",
    "1. **Primary Algorithm:** Item-based collaborative filtering\n",
    "   - Justification: 66-70% item connectivity vs. 0-52% user connectivity\n",
    "\n",
    "2. **For Sparse Users:** User-based CF with adaptive β-thresholds\n",
    "   - Justification: U1 has β=15, sufficient for neighborhood-based recommendations\n",
    "\n",
    "3. **For Active Users:** Matrix factorization (SVD, ALS) or neural CF\n",
    "   - Justification: U2 and U3 have β=0, requiring latent factor models\n",
    "\n",
    "4. **Bias Correction:** Implement mean-centering or z-score normalization\n",
    "   - Justification: 83% positive bias requires rating normalization\n",
    "\n",
    "5. **Long-Tail Mitigation:** Hybrid content-based + CF approach\n",
    "   - Justification: 79% tail items need content features to overcome sparsity\n",
    "\n",
    "---\n",
    "\n",
    "### 5.3 Future Work\n",
    "\n",
    "1. **Temporal Analysis:** Investigate if rating bias and long-tail distribution change over time\n",
    "2. **Social Network Integration:** Leverage the \"SocialRec\" aspect of the dataset to improve user similarity beyond co-ratings\n",
    "3. **Threshold Optimization:** Experiment with adaptive β-thresholds (e.g., 10%, 20%, 30%) based on user activity levels\n",
    "4. **Item Connectivity Analysis:** Compute β-equivalent metrics for items to validate item-based CF superiority\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
